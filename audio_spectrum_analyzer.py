#!/usr/bin/env python3
"""
éŸ³é¢‘é¢‘è°±åˆ†æå™¨
å®æ—¶åˆ†æéŸ³é¢‘é¢‘è°±ï¼Œæå–éŸ³é«˜å’Œå¼ºåº¦ä¿¡æ¯ç”¨äºè§†è§‰æ•ˆæœæ§åˆ¶
"""

import numpy as np
import threading
import time
from typing import Dict, List, Optional, Tuple
import math

try:
    import pygame
    PYGAME_AVAILABLE = True
except ImportError:
    PYGAME_AVAILABLE = False

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

try:
    import librosa
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False

class AudioSpectrumAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–éŸ³é¢‘é¢‘è°±åˆ†æå™¨"""
        
        # éŸ³é¢‘å‚æ•°
        self.sample_rate = 44100  # é‡‡æ ·ç‡
        self.chunk_size = 4096    # ç¼“å†²åŒºå¤§å°
        self.channels = 2         # ç«‹ä½“å£°
        
        # åˆ†æå‚æ•°
        self.fft_size = 2048      # FFTå¤§å°
        self.hop_size = 512       # è·³è·ƒå¤§å°
        self.overlap = self.fft_size - self.hop_size
        
        # é¢‘ç‡èŒƒå›´è®¾ç½®
        self.min_freq = 80.0      # æœ€ä½é¢‘ç‡ (Hz)
        self.max_freq = 2000.0    # æœ€é«˜é¢‘ç‡ (Hz)
        self.num_bands = 32       # é¢‘æ®µæ•°é‡
        
        # åˆ†æç»“æœå­˜å‚¨
        self.spectrum_data = {
            'frequencies': np.array([]),
            'magnitudes': np.array([]),
            'dominant_freq': 0.0,     # ä¸»å¯¼é¢‘ç‡
            'pitch_strength': 0.0,    # éŸ³é«˜å¼ºåº¦
            'overall_volume': 0.0,    # æ€»ä½“éŸ³é‡
            'frequency_bands': np.zeros(self.num_bands),  # åˆ†æ®µé¢‘è°±
            'pitch_class': 'C',       # éŸ³é«˜ç±»åˆ« (C, D, E, F, G, A, B)
            'octave': 4,              # å…«åº¦
            'note_confidence': 0.0,   # éŸ³ç¬¦è¯†åˆ«ç½®ä¿¡åº¦
            'timestamp': 0.0
        }
        
        # éŸ³é«˜åˆ°éŸ³ç¬¦çš„æ˜ å°„
        self.note_frequencies = {
            'C':  [65.41, 130.81, 261.63, 523.25, 1046.50],
            'C#': [69.30, 138.59, 277.18, 554.37, 1108.73],
            'D':  [73.42, 146.83, 293.66, 587.33, 1174.66],
            'D#': [77.78, 155.56, 311.13, 622.25, 1244.51],
            'E':  [82.41, 164.81, 329.63, 659.25, 1318.51],
            'F':  [87.31, 174.61, 349.23, 698.46, 1396.91],
            'F#': [92.50, 185.00, 369.99, 739.99, 1479.98],
            'G':  [98.00, 196.00, 392.00, 783.99, 1567.98],
            'G#': [103.83, 207.65, 415.30, 830.61, 1661.22],
            'A':  [110.00, 220.00, 440.00, 880.00, 1760.00],
            'A#': [116.54, 233.08, 466.16, 932.33, 1864.66],
            'B':  [123.47, 246.94, 493.88, 987.77, 1975.53]
        }
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.analysis_thread = None
        
        # éŸ³è½¨åˆ†ææ¨¡å¼
        self.track_analysis_mode = True  # æ˜¯å¦åˆ†æéŸ³è½¨è€Œä¸æ˜¯éº¦å…‹é£
        self.audio_manager = None        # éŸ³é¢‘ç®¡ç†å™¨å¼•ç”¨
        self.track_files = {
            1: "Fugue in G Trio violin-Violin.mp3",
            2: "Fugue in G Trio-Tenor_Lute.mp3", 
            3: "Fugue in G Trio Organ-Organ.mp3"
        }
        
        # éŸ³é¢‘è¾“å…¥
        self.audio_stream = None
        self.audio_buffer = np.zeros(self.chunk_size * 2)  # åŒç¼“å†²
        self.buffer_lock = threading.Lock()
        
        # å¹³æ»‘å¤„ç†
        self.smoothing_factor = 0.7
        self.prev_spectrum = np.zeros(self.num_bands)
        self.prev_pitch_strength = 0.0
        
        print("ğŸ¼ éŸ³é¢‘é¢‘è°±åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def set_audio_manager(self, audio_manager):
        """è®¾ç½®éŸ³é¢‘ç®¡ç†å™¨å¼•ç”¨"""
        self.audio_manager = audio_manager
        self.track_analysis_mode = True
        print("âœ… éŸ³é¢‘åˆ†æå™¨åˆ‡æ¢åˆ°éŸ³è½¨åˆ†ææ¨¡å¼")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–éŸ³é¢‘è¾“å…¥"""
        try:
            if not PYAUDIO_AVAILABLE:
                print("âš ï¸ PyAudioä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æå™¨")
                return self._initialize_mock_analyzer()
            
            import pyaudio
            
            # åˆå§‹åŒ–PyAudio
            self.p = pyaudio.PyAudio()
            
            # æ‰“å¼€éŸ³é¢‘æµ
            self.audio_stream = self.p.open(
                format=pyaudio.paFloat32,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=self._audio_callback
            )
            
            print("âœ… éŸ³é¢‘è¾“å…¥æµå·²æ‰“å¼€")
            return True
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥: {e}")
            return self._initialize_mock_analyzer()
    
    def _initialize_mock_analyzer(self) -> bool:
        """åˆå§‹åŒ–æ¨¡æ‹Ÿåˆ†æå™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        print("ğŸ”„ å¯ç”¨æ¨¡æ‹ŸéŸ³é¢‘åˆ†æå™¨")
        self.mock_mode = True
        self.mock_time_start = time.time()
        return True
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é¢‘æµå›è°ƒå‡½æ•°"""
        try:
            # è½¬æ¢éŸ³é¢‘æ•°æ®
            audio_data = np.frombuffer(in_data, dtype=np.float32)
            
            # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œå–å¹³å‡å€¼è½¬ä¸ºå•å£°é“
            if self.channels == 2:
                audio_data = audio_data.reshape(-1, 2).mean(axis=1)
            
            # æ›´æ–°ç¼“å†²åŒº
            with self.buffer_lock:
                self.audio_buffer[:-len(audio_data)] = self.audio_buffer[len(audio_data):]
                self.audio_buffer[-len(audio_data):] = audio_data
            
            return (None, pyaudio.paContinue)
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å›è°ƒé”™è¯¯: {e}")
            return (None, pyaudio.paComplete)
    
    def start_analysis(self):
        """å¼€å§‹é¢‘è°±åˆ†æ"""
        if self.is_running:
            return
        
        self.is_running = True
        
        # å¯åŠ¨éŸ³é¢‘æµ
        if hasattr(self, 'audio_stream') and self.audio_stream:
            self.audio_stream.start_stream()
        
        # å¯åŠ¨åˆ†æçº¿ç¨‹
        self.analysis_thread = threading.Thread(target=self._analysis_loop, daemon=True)
        self.analysis_thread.start()
        
        print("ğŸµ é¢‘è°±åˆ†æå·²å¯åŠ¨")
    
    def _analysis_loop(self):
        """åˆ†æå¾ªç¯"""
        window = np.hanning(self.fft_size)  # æ±‰å®çª—
        
        while self.is_running:
            try:
                if hasattr(self, 'mock_mode') and self.mock_mode:
                    # æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæµ‹è¯•æ•°æ®
                    self._generate_mock_spectrum()
                else:
                    # çœŸå®æ¨¡å¼ï¼šåˆ†æéŸ³é¢‘æ•°æ®
                    self._analyze_real_audio(window)
                
                time.sleep(1/60)  # 60 FPSæ›´æ–°é¢‘ç‡
                
            except Exception as e:
                print(f"âŒ åˆ†æå¾ªç¯é”™è¯¯: {e}")
                time.sleep(0.1)
    
    def _generate_mock_spectrum(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿé¢‘è°±æ•°æ®ï¼ˆåŸºäºæ­£åœ¨æ’­æ”¾çš„éŸ³è½¨ï¼‰"""
        current_time = time.time() - self.mock_time_start
        
        # æ£€æŸ¥å“ªäº›éŸ³è½¨æ­£åœ¨æ’­æ”¾
        active_tracks = []
        if self.audio_manager and hasattr(self.audio_manager, 'target_volumes'):
            for track_id, volume in self.audio_manager.target_volumes.items():
                if volume > 0.1:  # éŸ³é‡å¤§äº0.1è®¤ä¸ºæ˜¯æ¿€æ´»çš„
                    active_tracks.append(track_id)
        
        if not active_tracks:
            # æ²¡æœ‰æ¿€æ´»éŸ³è½¨æ—¶ä½¿ç”¨é™é»˜
            freq1, freq2, freq3 = 220, 440, 880
            volume = 0.05
        else:
            # æ ¹æ®æ¿€æ´»çš„éŸ³è½¨ç”Ÿæˆç›¸åº”çš„é¢‘è°±ç‰¹å¾
            freq1, freq2, freq3, volume = self._get_track_frequencies(active_tracks, current_time)
        
        # ç”Ÿæˆé¢‘è°±æ•°æ®
        freqs = np.linspace(self.min_freq, self.max_freq, self.num_bands)
        spectrum = np.zeros(self.num_bands)
        
        # åœ¨ä¸»è¦é¢‘ç‡é™„è¿‘æ·»åŠ èƒ½é‡
        for freq in [freq1, freq2, freq3]:
            if self.min_freq <= freq <= self.max_freq:
                idx = int((freq - self.min_freq) / (self.max_freq - self.min_freq) * self.num_bands)
                if 0 <= idx < self.num_bands:
                    spectrum[idx] += volume
        
        # æ·»åŠ ä¸€äº›å™ªéŸ³
        spectrum += np.random.normal(0, 0.01, self.num_bands)
        spectrum = np.maximum(0, spectrum)
        
        # å¹³æ»‘å¤„ç†
        spectrum = self.prev_spectrum * self.smoothing_factor + spectrum * (1 - self.smoothing_factor)
        self.prev_spectrum = spectrum
        
        # æ›´æ–°åˆ†æç»“æœ
        dominant_freq = freq1  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¢‘ç‡ä½œä¸ºä¸»å¯¼é¢‘ç‡
        pitch_strength = volume
        pitch_class, octave, confidence = self._frequency_to_note(dominant_freq)
        
        self.spectrum_data.update({
            'frequencies': freqs,
            'magnitudes': spectrum,
            'dominant_freq': dominant_freq,
            'pitch_strength': pitch_strength,
            'overall_volume': np.sum(spectrum),
            'frequency_bands': spectrum,
            'pitch_class': pitch_class,
            'octave': octave,
            'note_confidence': confidence,
            'timestamp': time.time()
        })
    
    def _analyze_real_audio(self, window):
        """åˆ†æçœŸå®éŸ³é¢‘æ•°æ®"""
        with self.buffer_lock:
            audio_chunk = self.audio_buffer[-self.fft_size:].copy()
        
        # åº”ç”¨çª—å‡½æ•°
        windowed_chunk = audio_chunk * window
        
        # æ‰§è¡ŒFFT
        fft_result = np.fft.rfft(windowed_chunk)
        magnitude_spectrum = np.abs(fft_result)
        
        # è®¡ç®—é¢‘ç‡è½´
        freqs = np.fft.rfftfreq(self.fft_size, 1/self.sample_rate)
        
        # æå–æŒ‡å®šé¢‘ç‡èŒƒå›´
        freq_mask = (freqs >= self.min_freq) & (freqs <= self.max_freq)
        valid_freqs = freqs[freq_mask]
        valid_magnitudes = magnitude_spectrum[freq_mask]
        
        # åˆ†æ®µåˆ†æ
        frequency_bands = self._compute_frequency_bands(valid_freqs, valid_magnitudes)
        
        # å¯»æ‰¾ä¸»å¯¼é¢‘ç‡
        if len(valid_magnitudes) > 0:
            peak_idx = np.argmax(valid_magnitudes)
            dominant_freq = valid_freqs[peak_idx]
            pitch_strength = valid_magnitudes[peak_idx] / np.max(valid_magnitudes)
        else:
            dominant_freq = 0.0
            pitch_strength = 0.0
        
        # å¹³æ»‘å¤„ç†
        pitch_strength = self.prev_pitch_strength * self.smoothing_factor + pitch_strength * (1 - self.smoothing_factor)
        self.prev_pitch_strength = pitch_strength
        
        frequency_bands = self.prev_spectrum * self.smoothing_factor + frequency_bands * (1 - self.smoothing_factor)
        self.prev_spectrum = frequency_bands
        
        # éŸ³ç¬¦è¯†åˆ«
        pitch_class, octave, confidence = self._frequency_to_note(dominant_freq)
        
        # æ›´æ–°ç»“æœ
        self.spectrum_data.update({
            'frequencies': valid_freqs,
            'magnitudes': valid_magnitudes,
            'dominant_freq': dominant_freq,
            'pitch_strength': pitch_strength,
            'overall_volume': np.sum(valid_magnitudes),
            'frequency_bands': frequency_bands,
            'pitch_class': pitch_class,
            'octave': octave,
            'note_confidence': confidence,
            'timestamp': time.time()
        })
    
    def _compute_frequency_bands(self, freqs: np.ndarray, magnitudes: np.ndarray) -> np.ndarray:
        """è®¡ç®—é¢‘æ®µèƒ½é‡"""
        bands = np.zeros(self.num_bands)
        
        if len(freqs) == 0:
            return bands
        
        # å¯¹æ•°åˆ†å¸ƒçš„é¢‘æ®µè¾¹ç•Œ
        freq_min = self.min_freq
        freq_max = self.max_freq
        
        for i in range(self.num_bands):
            # è®¡ç®—æ¯ä¸ªé¢‘æ®µçš„è¾¹ç•Œ
            band_start = freq_min * (freq_max / freq_min) ** (i / self.num_bands)
            band_end = freq_min * (freq_max / freq_min) ** ((i + 1) / self.num_bands)
            
            # æ‰¾åˆ°é¢‘æ®µå†…çš„é¢‘ç‡
            band_mask = (freqs >= band_start) & (freqs < band_end)
            if np.any(band_mask):
                bands[i] = np.mean(magnitudes[band_mask])
        
        return bands
    
    def _frequency_to_note(self, frequency: float) -> Tuple[str, int, float]:
        """å°†é¢‘ç‡è½¬æ¢ä¸ºéŸ³ç¬¦"""
        if frequency < 20:  # å¤ªä½çš„é¢‘ç‡
            return 'C', 4, 0.0
        
        # è®¡ç®—ä¸A4 (440Hz)çš„åŠéŸ³æ•°å·®å¼‚
        A4_freq = 440.0
        semitones_from_A4 = 12 * math.log2(frequency / A4_freq)
        
        # å››èˆäº”å…¥åˆ°æœ€è¿‘çš„åŠéŸ³
        nearest_semitone = round(semitones_from_A4)
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆé¢‘ç‡ä¸æ ‡å‡†é¢‘ç‡çš„æ¥è¿‘ç¨‹åº¦ï¼‰
        standard_freq = A4_freq * (2 ** (nearest_semitone / 12))
        confidence = max(0, 1 - abs(frequency - standard_freq) / standard_freq)
        
        # è½¬æ¢ä¸ºéŸ³ç¬¦åç§°å’Œå…«åº¦
        note_names = ['A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#']
        note_index = nearest_semitone % 12
        note_name = note_names[note_index]
        
        # è®¡ç®—å…«åº¦
        octave = 4 + (nearest_semitone + 9) // 12  # +9 å› ä¸ºä»Aå¼€å§‹è®¡ç®—
        
        return note_name, octave, confidence
    
    def _get_track_frequencies(self, active_tracks, current_time):
        """æ ¹æ®æ¿€æ´»çš„éŸ³è½¨ç”Ÿæˆç›¸åº”çš„é¢‘ç‡ç‰¹å¾"""
        # ä¸åŒéŸ³è½¨çš„ç‰¹å¾é¢‘ç‡èŒƒå›´
        track_characteristics = {
            1: {  # å°æç´ - é«˜éŸ³åŸŸ
                'base_freq': 440,  # A4
                'freq_range': 150,
                'harmonics': [1, 2, 3, 5],  # ä¸°å¯Œçš„æ³›éŸ³
                'vibrato_rate': 0.8,
                'volume_factor': 0.6
            },
            2: {  # é²ç‰¹ç´ - ä¸­éŸ³åŸŸ
                'base_freq': 330,  # E4
                'freq_range': 80, 
                'harmonics': [1, 1.5, 2, 3],  # å¼¦ä¹å™¨ç‰¹å¾æ³›éŸ³
                'vibrato_rate': 0.5,
                'volume_factor': 0.5
            },
            3: {  # ç®¡é£ç´ - ä½éŸ³åŸŸ
                'base_freq': 220,  # A3
                'freq_range': 60,
                'harmonics': [1, 2, 4, 8],  # ç®¡é£ç´ç‰¹å¾æ³›éŸ³
                'vibrato_rate': 0.3,
                'volume_factor': 0.8
            }
        }
        
        # åˆæˆæ¿€æ´»éŸ³è½¨çš„é¢‘ç‡ç‰¹å¾
        freq1, freq2, freq3 = 0, 0, 0
        total_volume = 0
        
        for track_id in active_tracks:
            if track_id in track_characteristics:
                char = track_characteristics[track_id]
                track_volume = self.audio_manager.target_volumes.get(track_id, 0.0)
                
                # ä¸ºæ¯ä¸ªéŸ³è½¨ç”Ÿæˆä¸»é¢‘ç‡
                base_freq = char['base_freq']
                vibrato = char['freq_range'] * 0.3 * math.sin(current_time * char['vibrato_rate'])
                track_freq = base_freq + vibrato
                
                # åŠ æƒåˆæˆåˆ°æ€»é¢‘ç‡
                weight = track_volume * char['volume_factor']
                freq1 += track_freq * weight
                freq2 += track_freq * char['harmonics'][1] * weight * 0.7
                freq3 += track_freq * char['harmonics'][2] * weight * 0.5
                
                total_volume += track_volume * char['volume_factor']
        
        # å½’ä¸€åŒ–
        if total_volume > 0:
            freq1 /= len(active_tracks)
            freq2 /= len(active_tracks) 
            freq3 /= len(active_tracks)
        
        # æ·»åŠ éŸ³ä¹æ€§çš„æ—¶é—´å˜åŒ–
        freq1 += 20 * math.sin(current_time * 0.4)
        freq2 += 15 * math.cos(current_time * 0.6)
        freq3 += 10 * math.sin(current_time * 0.8)
        
        # éŸ³é‡å˜åŒ–
        volume = 0.2 + total_volume * 0.6 + 0.1 * math.sin(current_time * 1.5)
        
        return freq1, freq2, freq3, min(volume, 1.0)
    
    def get_pitch_intensity(self) -> float:
        """è·å–éŸ³é«˜å¼ºåº¦ï¼ˆç”¨äºæ§åˆ¶ç²’å­å¤§å°ï¼‰"""
        # ç»“åˆä¸»å¯¼é¢‘ç‡å¼ºåº¦å’Œæ€»ä½“éŸ³é‡
        pitch_factor = self.spectrum_data['pitch_strength']
        volume_factor = self.spectrum_data['overall_volume'] / 100.0  # å½’ä¸€åŒ–
        
        # åŠ æƒç»„åˆ
        intensity = pitch_factor * 0.7 + volume_factor * 0.3
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        return max(0.0, min(2.0, intensity))
    
    def get_frequency_bands_normalized(self) -> np.ndarray:
        """è·å–å½’ä¸€åŒ–çš„é¢‘æ®µæ•°æ®"""
        bands = self.spectrum_data['frequency_bands']
        if np.max(bands) > 0:
            return bands / np.max(bands)
        return bands
    
    def get_status_info(self) -> dict:
        """è·å–åˆ†æå™¨çŠ¶æ€ä¿¡æ¯"""
        return {
            'is_running': self.is_running,
            'dominant_freq': self.spectrum_data['dominant_freq'],
            'pitch_strength': self.spectrum_data['pitch_strength'],
            'overall_volume': self.spectrum_data['overall_volume'],
            'pitch_class': self.spectrum_data['pitch_class'],
            'octave': self.spectrum_data['octave'],
            'note_confidence': self.spectrum_data['note_confidence'],
            'pitch_intensity': self.get_pitch_intensity(),
            'timestamp': self.spectrum_data['timestamp']
        }
    
    def stop_analysis(self):
        """åœæ­¢é¢‘è°±åˆ†æ"""
        self.is_running = False
        
        if self.analysis_thread and self.analysis_thread.is_alive():
            self.analysis_thread.join(timeout=1.0)
        
        if hasattr(self, 'audio_stream') and self.audio_stream:
            self.audio_stream.stop_stream()
            self.audio_stream.close()
        
        if hasattr(self, 'p'):
            self.p.terminate()
        
        print("ğŸµ é¢‘è°±åˆ†æå·²åœæ­¢")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop_analysis()
        print("âœ… éŸ³é¢‘åˆ†æå™¨å·²æ¸…ç†")