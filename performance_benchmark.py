#!/usr/bin/env python3
"""
Performance Benchmark and Analysis Tool
æ‰‹åŠ¿æ§åˆ¶éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·

ä¸»è¦åŠŸèƒ½ï¼š
- CPU/å†…å­˜ä½¿ç”¨ç‡ç›‘æ§
- å¸§ç‡æ€§èƒ½æµ‹è¯•
- éŸ³é¢‘å»¶è¿Ÿæµ‹é‡
- ç³»ç»Ÿè´Ÿè½½åˆ†æ
- å¹³å°ç‰¹å®šä¼˜åŒ–å»ºè®®

Author: Performance Engineer
Date: 2025-10-05
"""

import time
import psutil
import threading
import numpy as np
import cv2
import pygame
import gc
import sys
import os
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import deque
import json
import platform
from contextlib import contextmanager


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: float
    cpu_percent: float
    memory_mb: float
    memory_percent: float
    fps: float
    frame_time_ms: float
    audio_latency_ms: float
    gesture_processing_time_ms: float
    active_threads: int
    gpu_usage_percent: float = 0.0  # macOS Metal APIç›‘æ§


@dataclass
class SystemInfo:
    """ç³»ç»Ÿä¿¡æ¯"""
    platform: str = field(default_factory=lambda: platform.system())
    cpu_count: int = field(default_factory=lambda: psutil.cpu_count())
    memory_total_gb: float = field(default_factory=lambda: psutil.virtual_memory().total / (1024**3))
    python_version: str = field(default_factory=lambda: sys.version)
    opencv_version: str = field(default_factory=lambda: cv2.__version__)
    pygame_version: str = field(default_factory=lambda: pygame.version.ver)


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨ - å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½"""

    def __init__(self, max_history: int = 1000):
        """
        åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨

        Args:
            max_history: æœ€å¤§å†å²è®°å½•æ•°é‡
        """
        self.max_history = max_history
        self.metrics_history: deque = deque(maxlen=max_history)
        self.system_info = SystemInfo()

        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.monitor_interval = 0.1  # 100msç›‘æ§é—´éš”

        # æ€§èƒ½ç›®æ ‡
        self.target_fps = 30
        self.target_memory_mb = 500
        self.target_cpu_percent = 60
        self.target_audio_latency_ms = 50

        # å½“å‰ç›‘æ§å€¼
        self.current_fps = 0.0
        self.current_frame_time = 0.0
        self.frame_count = 0
        self.last_frame_time = time.time()

        # å®šæ—¶å™¨
        self.timers: Dict[str, float] = {}

        # è­¦å‘ŠçŠ¶æ€
        self.performance_warnings: List[str] = []

    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if not self.is_monitoring:
            self.is_monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self.monitor_thread.start()
            print("Performance monitoring started")

    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=1.0)
        print("Performance monitoring stopped")

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                cpu_percent = psutil.cpu_percent(interval=None)
                memory_info = psutil.virtual_memory()
                memory_mb = memory_info.used / (1024**2)
                memory_percent = memory_info.percent

                # è®¡ç®—FPS
                current_time = time.time()
                if self.frame_count > 0:
                    time_diff = current_time - self.last_frame_time
                    if time_diff > 0:
                        self.current_fps = 1.0 / time_diff
                        self.current_frame_time = time_diff * 1000  # ms

                # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
                metrics = PerformanceMetrics(
                    timestamp=current_time,
                    cpu_percent=cpu_percent,
                    memory_mb=memory_mb,
                    memory_percent=memory_percent,
                    fps=self.current_fps,
                    frame_time_ms=self.current_frame_time,
                    audio_latency_ms=self._measure_audio_latency(),
                    gesture_processing_time_ms=self.timers.get('gesture_processing', 0),
                    active_threads=threading.active_count(),
                    gpu_usage_percent=self._get_gpu_usage()
                )

                self.metrics_history.append(metrics)
                self._check_performance_warnings(metrics)

                time.sleep(self.monitor_interval)

            except Exception as e:
                print(f"Monitoring error: {e}")
                time.sleep(self.monitor_interval)

    def _measure_audio_latency(self) -> float:
        """æµ‹é‡éŸ³é¢‘å»¶è¿Ÿï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´ç²¾ç¡®çš„éŸ³é¢‘å»¶è¿Ÿæµ‹é‡
        # ç›®å‰è¿”å›pygame mixerçš„ç¼“å†²åŒºå»¶è¿Ÿä¼°ç®—
        try:
            if pygame.mixer.get_init():
                # æ ¹æ®ç¼“å†²åŒºå¤§å°ä¼°ç®—å»¶è¿Ÿ
                frequency, size, channels = pygame.mixer.get_init()
                buffer_size = 512  # é»˜è®¤ç¼“å†²åŒºå¤§å°
                latency_ms = (buffer_size / frequency) * 1000
                return latency_ms
        except:
            pass
        return 0.0

    def _get_gpu_usage(self) -> float:
        """è·å–GPUä½¿ç”¨ç‡ï¼ˆmacOS Metal APIï¼‰"""
        # macOSç‰¹å®šçš„GPUç›‘æ§
        if self.system_info.platform == "Darwin":
            try:
                # ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤è·å–GPUä¿¡æ¯
                import subprocess
                result = subprocess.run(
                    ["system_profiler", "SPDisplaysDataType", "-json"],
                    capture_output=True, text=True, timeout=1
                )
                # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å®ç°éœ€è¦è§£æJSON
                return 0.0  # å ä½ç¬¦
            except:
                return 0.0
        return 0.0

    def _check_performance_warnings(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥æ€§èƒ½è­¦å‘Š"""
        warnings = []

        if metrics.fps < self.target_fps * 0.8:
            warnings.append(f"Low FPS: {metrics.fps:.1f} < {self.target_fps}")

        if metrics.memory_mb > self.target_memory_mb:
            warnings.append(f"High memory usage: {metrics.memory_mb:.1f}MB > {self.target_memory_mb}MB")

        if metrics.cpu_percent > self.target_cpu_percent:
            warnings.append(f"High CPU usage: {metrics.cpu_percent:.1f}% > {self.target_cpu_percent}%")

        if metrics.audio_latency_ms > self.target_audio_latency_ms:
            warnings.append(f"High audio latency: {metrics.audio_latency_ms:.1f}ms > {self.target_audio_latency_ms}ms")

        self.performance_warnings = warnings

    @contextmanager
    def timer(self, name: str):
        """è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        try:
            yield
        finally:
            elapsed_time = (time.time() - start_time) * 1000  # ms
            self.timers[name] = elapsed_time

    def record_frame(self):
        """è®°å½•å¸§è®¡æ•°"""
        self.frame_count += 1
        self.last_frame_time = time.time()

    def get_current_metrics(self) -> Optional[PerformanceMetrics]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        if self.metrics_history:
            return self.metrics_history[-1]
        return None

    def get_average_metrics(self, window_seconds: float = 5.0) -> Dict[str, float]:
        """è·å–å¹³å‡æ€§èƒ½æŒ‡æ ‡"""
        if not self.metrics_history:
            return {}

        current_time = time.time()
        cutoff_time = current_time - window_seconds

        # ç­›é€‰æ—¶é—´çª—å£å†…çš„æ•°æ®
        recent_metrics = [
            m for m in self.metrics_history
            if m.timestamp >= cutoff_time
        ]

        if not recent_metrics:
            return {}

        return {
            'avg_fps': np.mean([m.fps for m in recent_metrics]),
            'avg_cpu_percent': np.mean([m.cpu_percent for m in recent_metrics]),
            'avg_memory_mb': np.mean([m.memory_mb for m in recent_metrics]),
            'avg_frame_time_ms': np.mean([m.frame_time_ms for m in recent_metrics]),
            'avg_audio_latency_ms': np.mean([m.audio_latency_ms for m in recent_metrics]),
            'max_cpu_percent': np.max([m.cpu_percent for m in recent_metrics]),
            'max_memory_mb': np.max([m.memory_mb for m in recent_metrics]),
            'min_fps': np.min([m.fps for m in recent_metrics])
        }

    def get_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        current = self.get_current_metrics()
        averages = self.get_average_metrics()

        report = {
            'system_info': {
                'platform': self.system_info.platform,
                'cpu_count': self.system_info.cpu_count,
                'memory_total_gb': self.system_info.memory_total_gb,
                'python_version': self.system_info.python_version.split()[0],
                'opencv_version': self.system_info.opencv_version,
                'pygame_version': self.system_info.pygame_version
            },
            'current_metrics': current.__dict__ if current else {},
            'average_metrics': averages,
            'performance_targets': {
                'target_fps': self.target_fps,
                'target_memory_mb': self.target_memory_mb,
                'target_cpu_percent': self.target_cpu_percent,
                'target_audio_latency_ms': self.target_audio_latency_ms
            },
            'warnings': self.performance_warnings,
            'optimization_recommendations': self._generate_recommendations()
        }

        return report

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        averages = self.get_average_metrics()

        if not averages:
            return recommendations

        # FPSä¼˜åŒ–å»ºè®®
        if averages.get('avg_fps', 30) < self.target_fps * 0.8:
            recommendations.extend([
                "è€ƒè™‘å®ç°å¸§è·³è·ƒç­–ç•¥ï¼šæ¯2å¸§å¤„ç†ä¸€æ¬¡æ‰‹åŠ¿æ£€æµ‹",
                "é™ä½MediaPipeæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼åˆ°0.5",
                "å‡å°‘è§†é¢‘å¤„ç†åˆ†è¾¨ç‡åˆ°320x240",
                "ä½¿ç”¨å¤šçº¿ç¨‹åˆ†ç¦»æ‰‹åŠ¿æ£€æµ‹å’Œæ¸²æŸ“"
            ])

        # å†…å­˜ä¼˜åŒ–å»ºè®®
        if averages.get('avg_memory_mb', 0) > self.target_memory_mb:
            recommendations.extend([
                "å®ç°numpyæ•°ç»„å¯¹è±¡æ± é‡ç”¨",
                "å®šæœŸè°ƒç”¨gc.collect()è¿›è¡Œåƒåœ¾å›æ”¶",
                "é™åˆ¶MediaPipeå†å²ç¼“å­˜å¤§å°",
                "ä¼˜åŒ–OpenCV Matå¯¹è±¡ç”Ÿå‘½å‘¨æœŸ"
            ])

        # CPUä¼˜åŒ–å»ºè®®
        if averages.get('avg_cpu_percent', 0) > self.target_cpu_percent:
            recommendations.extend([
                "ä½¿ç”¨æ›´é«˜æ•ˆçš„é¢œè‰²ç©ºé—´è½¬æ¢",
                "å‡å°‘éŸ³é¢‘æ›´æ–°é¢‘ç‡åˆ°15Hz",
                "å¯ç”¨pygameç¡¬ä»¶åŠ é€Ÿ",
                "ä¼˜åŒ–æ‰‹åŠ¿æ£€æµ‹ç®—æ³•å¤æ‚åº¦"
            ])

        # éŸ³é¢‘å»¶è¿Ÿä¼˜åŒ–
        if averages.get('avg_audio_latency_ms', 0) > self.target_audio_latency_ms:
            recommendations.extend([
                "å‡å°pygame mixerç¼“å†²åŒºåˆ°256å­—èŠ‚",
                "ä½¿ç”¨ä¸“ç”¨éŸ³é¢‘çº¿ç¨‹",
                "è€ƒè™‘ä½¿ç”¨ASIOéŸ³é¢‘é©±åŠ¨",
                "ä¼˜åŒ–éŸ³é‡æ¸å˜ç®—æ³•"
            ])

        # macOSç‰¹å®šä¼˜åŒ–
        if self.system_info.platform == "Darwin":
            recommendations.extend([
                "å¯ç”¨Metal Performance ShadersåŠ é€Ÿ",
                "ä½¿ç”¨Core Audioä½å»¶è¿Ÿæ¨¡å¼",
                "ä¼˜åŒ–çº¿ç¨‹è°ƒåº¦å™¨äº²å’Œæ€§",
                "å¯ç”¨è‡ªåŠ¨å¼•ç”¨è®¡æ•°ä¼˜åŒ–"
            ])

        return recommendations

    def save_report(self, filename: str = None):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"performance_report_{timestamp}.json"

        report = self.get_performance_report()

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        print(f"Performance report saved to: {filename}")
        return filename


class BenchmarkRunner:
    """åŸºå‡†æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, profiler: PerformanceProfiler):
        self.profiler = profiler

    def run_gesture_detection_benchmark(self, duration_seconds: int = 30) -> Dict[str, float]:
        """è¿è¡Œæ‰‹åŠ¿æ£€æµ‹æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print(f"Running gesture detection benchmark for {duration_seconds} seconds...")

        # æ¨¡æ‹Ÿæ‰‹åŠ¿æ£€æµ‹è´Ÿè½½
        import cv2
        import mediapipe as mp

        mp_hands = mp.solutions.hands
        hands = mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )

        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

        start_time = time.time()
        frame_count = 0
        processing_times = []

        while time.time() - start_time < duration_seconds:
            with self.profiler.timer('gesture_processing'):
                # æ¨¡æ‹Ÿæ‰‹åŠ¿æ£€æµ‹
                rgb_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)
                results = hands.process(rgb_image)

                # ç®€å•çš„åå¤„ç†
                if results.multi_hand_landmarks:
                    for hand_landmarks in results.multi_hand_landmarks:
                        landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]

            processing_times.append(self.profiler.timers.get('gesture_processing', 0))
            frame_count += 1
            self.profiler.record_frame()

            # æ§åˆ¶å¸§ç‡
            time.sleep(1/60)  # ç›®æ ‡60FPS

        hands.close()

        return {
            'total_frames': frame_count,
            'avg_fps': frame_count / duration_seconds,
            'avg_processing_time_ms': np.mean(processing_times),
            'max_processing_time_ms': np.max(processing_times),
            'min_processing_time_ms': np.min(processing_times),
            'std_processing_time_ms': np.std(processing_times)
        }

    def run_audio_latency_benchmark(self, test_duration: int = 10) -> Dict[str, float]:
        """è¿è¡ŒéŸ³é¢‘å»¶è¿ŸåŸºå‡†æµ‹è¯•"""
        print(f"Running audio latency benchmark for {test_duration} seconds...")

        # åˆå§‹åŒ–pygame mixer
        pygame.mixer.pre_init(frequency=44100, size=-16, channels=2, buffer=256)
        pygame.mixer.init()

        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        sample_rate = 44100
        duration = 0.1  # 100msæµ‹è¯•éŸ³é¢‘
        t = np.linspace(0, duration, int(sample_rate * duration))
        test_audio = np.sin(2 * np.pi * 440 * t)  # 440Hzæ­£å¼¦æ³¢

        # è½¬æ¢ä¸ºpygameæ ¼å¼
        test_audio_int = (test_audio * 32767).astype(np.int16)
        stereo_audio = np.array([test_audio_int, test_audio_int]).T
        test_sound = pygame.sndarray.make_sound(stereo_audio)

        latencies = []
        start_time = time.time()

        while time.time() - start_time < test_duration:
            # æµ‹é‡æ’­æ”¾å»¶è¿Ÿ
            play_start = time.time()
            test_sound.play()

            # ç­‰å¾…éŸ³é¢‘å¼€å§‹æ’­æ”¾
            while pygame.mixer.get_busy():
                pass

            play_end = time.time()
            latency_ms = (play_end - play_start) * 1000
            latencies.append(latency_ms)

            time.sleep(0.1)  # 100msé—´éš”

        pygame.mixer.quit()

        return {
            'avg_latency_ms': np.mean(latencies),
            'max_latency_ms': np.max(latencies),
            'min_latency_ms': np.min(latencies),
            'std_latency_ms': np.std(latencies),
            'samples_count': len(latencies)
        }

    def run_memory_stress_test(self, duration_seconds: int = 60) -> Dict[str, float]:
        """è¿è¡Œå†…å­˜å‹åŠ›æµ‹è¯•"""
        print(f"Running memory stress test for {duration_seconds} seconds...")

        initial_memory = psutil.Process().memory_info().rss / (1024**2)
        memory_samples = []

        # æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨æ¨¡å¼
        data_arrays = []
        start_time = time.time()

        while time.time() - start_time < duration_seconds:
            # æ¨¡æ‹Ÿè§†é¢‘å¸§å¤„ç†
            frame_data = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            processed_frame = cv2.cvtColor(frame_data, cv2.COLOR_BGR2RGB)

            # æ¨¡æ‹Ÿç‰¹å¾æå–
            features = np.random.random((21, 3))

            # å‘¨æœŸæ€§æ¸…ç†
            if len(data_arrays) > 100:
                data_arrays = data_arrays[-50:]  # ä¿ç•™æœ€è¿‘50ä¸ª
                gc.collect()

            data_arrays.append((processed_frame, features))

            current_memory = psutil.Process().memory_info().rss / (1024**2)
            memory_samples.append(current_memory)

            time.sleep(0.033)  # ~30FPS

        # æ¸…ç†
        data_arrays.clear()
        gc.collect()

        final_memory = psutil.Process().memory_info().rss / (1024**2)

        return {
            'initial_memory_mb': initial_memory,
            'final_memory_mb': final_memory,
            'peak_memory_mb': np.max(memory_samples),
            'avg_memory_mb': np.mean(memory_samples),
            'memory_growth_mb': final_memory - initial_memory,
            'memory_variance': np.var(memory_samples)
        }


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("Performance Benchmark Tool")
    print("=" * 50)

    # åˆ›å»ºæ€§èƒ½åˆ†æå™¨
    profiler = PerformanceProfiler()
    profiler.start_monitoring()

    try:
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        runner = BenchmarkRunner(profiler)

        print("\n1. Running gesture detection benchmark...")
        gesture_results = runner.run_gesture_detection_benchmark(30)

        print("\n2. Running audio latency benchmark...")
        audio_results = runner.run_audio_latency_benchmark(10)

        print("\n3. Running memory stress test...")
        memory_results = runner.run_memory_stress_test(60)

        # ç­‰å¾…æ”¶é›†è¶³å¤Ÿçš„ç›‘æ§æ•°æ®
        time.sleep(2)

        # ç”ŸæˆæŠ¥å‘Š
        print("\n4. Generating performance report...")
        report = profiler.get_performance_report()

        # æ·»åŠ åŸºå‡†æµ‹è¯•ç»“æœ
        report['benchmark_results'] = {
            'gesture_detection': gesture_results,
            'audio_latency': audio_results,
            'memory_stress': memory_results
        }

        # ä¿å­˜æŠ¥å‘Š
        filename = profiler.save_report()

        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "=" * 50)
        print("PERFORMANCE SUMMARY")
        print("=" * 50)

        if profiler.performance_warnings:
            print("âš ï¸  PERFORMANCE WARNINGS:")
            for warning in profiler.performance_warnings:
                print(f"   - {warning}")
        else:
            print("âœ… No performance warnings detected")

        print(f"\nğŸ“Š Gesture Detection:")
        print(f"   - Average FPS: {gesture_results['avg_fps']:.1f}")
        print(f"   - Average processing time: {gesture_results['avg_processing_time_ms']:.1f}ms")

        print(f"\nğŸ”Š Audio Latency:")
        print(f"   - Average latency: {audio_results['avg_latency_ms']:.1f}ms")

        print(f"\nğŸ’¾ Memory Usage:")
        print(f"   - Peak memory: {memory_results['peak_memory_mb']:.1f}MB")
        print(f"   - Memory growth: {memory_results['memory_growth_mb']:.1f}MB")

        print(f"\nğŸ“‹ Top Optimization Recommendations:")
        recommendations = report['optimization_recommendations'][:5]
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")

        print(f"\nğŸ“„ Full report saved to: {filename}")

    except KeyboardInterrupt:
        print("\nBenchmark interrupted by user")

    finally:
        profiler.stop_monitoring()


if __name__ == "__main__":
    main()