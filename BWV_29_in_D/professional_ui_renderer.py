#!/usr/bin/env python3
"""
BWV_29_in_D ä¸“ä¸šæŒ‡æŒ¥å®¶æ§åˆ¶ç•Œé¢æ¸²æŸ“å™¨
ä¸ºæŒ‡æŒ¥å®¶æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿè®¾è®¡çš„ä¸“ä¸šçº§å®æ—¶çŠ¶æ€æ˜¾ç¤ºç•Œé¢

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ä¸“ä¸šéŸ³ä¹åˆ¶ä½œé£æ ¼çš„ç•Œé¢è®¾è®¡
- å®æ—¶7å£°éƒ¨å¯è§†åŒ–è¾¹ç•Œå’Œæ¿€æ´»çŠ¶æ€
- åŠ¨æ€éŸ³é¢‘ç”µå¹³è¡¨å’Œé¢‘è°±æ˜¾ç¤º
- æ‰‹åŠ¿è½¨è¿¹è¿½è¸ªå’ŒæŒ‡æŒ¥åˆ†æ
- æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•ä¿¡æ¯é¢æ¿
- å“åº”å¼å¸ƒå±€å’ŒåŠ¨ç”»æ•ˆæœ

Author: Claude Code
Date: 2025-10-05
"""

import cv2
import numpy as np
import time
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
from collections import deque
import colorsys


class ProfessionalUIRenderer:
    """ä¸“ä¸šæŒ‡æŒ¥å®¶æ§åˆ¶ç•Œé¢æ¸²æŸ“å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–ä¸“ä¸šUIæ¸²æŸ“å™¨"""
        # ä¸“ä¸šéŸ³ä¹åˆ¶ä½œé£æ ¼é¢œè‰²æ–¹æ¡ˆ
        self.colors = {
            # ä¸»è¦ç•Œé¢é¢œè‰²
            'bg_dark': (26, 26, 26),        # æ·±è‰²èƒŒæ™¯ #1a1a1a
            'bg_medium': (45, 45, 45),      # ä¸­ç­‰èƒŒæ™¯ #2d2d2d
            'bg_light': (64, 64, 64),       # æµ…è‰²èƒŒæ™¯ #404040
            'bg_panel': (35, 35, 35),       # é¢æ¿èƒŒæ™¯ #232323

            # æ–‡æœ¬é¢œè‰²
            'text_primary': (255, 255, 255),    # ä¸»è¦æ–‡æœ¬ - ç™½è‰²
            'text_secondary': (200, 200, 200),  # æ¬¡è¦æ–‡æœ¬ - æµ…ç°
            'text_muted': (140, 140, 140),      # é™éŸ³æ–‡æœ¬ - ç°è‰²
            'text_accent': (255, 215, 0),       # å¼ºè°ƒæ–‡æœ¬ - é‡‘è‰²

            # çŠ¶æ€é¢œè‰²
            'active_green': (76, 255, 76),      # æ¿€æ´»ç»¿è‰² #4cff4c
            'active_yellow': (255, 255, 76),    # æ¿€æ´»é»„è‰² #ffff4c
            'warning_orange': (255, 165, 0),    # è­¦å‘Šæ©™è‰² #ffa500
            'error_red': (255, 76, 76),         # é”™è¯¯çº¢è‰² #ff4c4c
            'paused_blue': (76, 153, 255),      # æš‚åœè“è‰² #4c99ff
            'conducting_gold': (255, 215, 0),   # æŒ‡æŒ¥é‡‘è‰² #ffd700

            # 7ä¸ªå£°éƒ¨ä¸“ä¸šè°ƒè‰²æ¿
            'voice_colors': [
                (255, 99, 71),    # 1. Tromba - ç•ªèŒ„çº¢ (é“œç®¡)
                (138, 43, 226),   # 2. Violins - è“ç´«è‰² (å¼¦ä¹)
                (255, 140, 0),    # 3. Viola - æ©™è‰² (ä¸­éŸ³å¼¦ä¹)
                (50, 205, 50),    # 4. Oboe - é…¸æ©™ç»¿ (æœ¨ç®¡)
                (30, 144, 255),   # 5. Continuo - é“å¥‡è“ (æ•°å­—ä½éŸ³)
                (255, 20, 147),   # 6. Organo - æ·±ç²‰è‰² (ç®¡é£ç´)
                (255, 215, 0)     # 7. Timpani - é‡‘è‰² (æ‰“å‡»ä¹)
            ],

            # éŸ³é¢‘ç”µå¹³é¢œè‰² (ä¸“ä¸šéŸ³é¢‘è®¾å¤‡é£æ ¼)
            'level_low': (76, 255, 76),      # ä½ç”µå¹³ - ç»¿è‰²
            'level_mid': (255, 255, 76),     # ä¸­ç”µå¹³ - é»„è‰²
            'level_high': (255, 165, 0),     # é«˜ç”µå¹³ - æ©™è‰²
            'level_peak': (255, 76, 76),     # å³°å€¼ - çº¢è‰²
            'level_bg': (20, 20, 20),        # ç”µå¹³èƒŒæ™¯ - æ·±ç°

            # ç‰¹æ®Šæ•ˆæœ
            'glow_effect': (255, 255, 255),  # å‘å…‰æ•ˆæœ
            'shadow': (0, 0, 0),             # é˜´å½±
            'grid_line': (60, 60, 60),       # ç½‘æ ¼çº¿
            'border_accent': (100, 100, 100), # è¾¹æ¡†å¼ºè°ƒ
        }

        # å­—ä½“è®¾ç½®
        self.fonts = {
            'title': cv2.FONT_HERSHEY_SIMPLEX,
            'subtitle': cv2.FONT_HERSHEY_SIMPLEX,
            'body': cv2.FONT_HERSHEY_SIMPLEX,
            'mono': cv2.FONT_HERSHEY_DUPLEX,
            'small': cv2.FONT_HERSHEY_SIMPLEX
        }

        self.font_scales = {
            'title': 0.9,
            'subtitle': 0.7,
            'body': 0.5,
            'small': 0.4,
            'tiny': 0.3
        }

        self.thickness = {
            'thin': 1,
            'normal': 2,
            'thick': 3,
            'bold': 4
        }

        # å¸ƒå±€å‚æ•° (å“åº”å¼è®¾è®¡)
        self.layout = {
            'header_height': 120,
            'footer_height': 180,
            'sidebar_width': 260,
            'panel_margin': 12,
            'text_margin': 8,
            'line_spacing': 22,
            'corner_radius': 8,
            'border_width': 2
        }

        # åŠ¨ç”»å’Œæ•ˆæœå‚æ•°
        self.animation = {
            'pulse_speed': 0.05,
            'fade_speed': 0.02,
            'glow_intensity': 0.4,
            'bounce_factor': 1.2,
            'transition_speed': 0.1
        }

        # å†å²æ•°æ®ç¼“å­˜ (ç”¨äºåŠ¨æ€æ•ˆæœ)
        self.history = {
            'volume_levels': {},
            'gesture_strength': deque(maxlen=60),  # 1ç§’å†å² (60FPS)
            'fps_history': deque(maxlen=30),       # 0.5ç§’å†å²
            'conducting_analysis': deque(maxlen=100), # æŒ‡æŒ¥åˆ†æå†å²
            'hand_positions': deque(maxlen=30),    # æ‰‹éƒ¨ä½ç½®å†å²
            'max_history_length': 120
        }

        # æ—¶é—´è·Ÿè¸ª
        self.last_update_time = time.time()
        self.animation_time = 0.0
        self.frame_count = 0

        # ç‰¹æ•ˆç¼“å­˜
        self.effects_cache = {
            'glow_masks': {},
            'gradient_cache': {},
            'particle_systems': []
        }

        # æŒ‡æŒ¥åˆ†æçŠ¶æ€
        self.conducting_analysis = {
            'tempo_detection': 0.0,
            'rhythm_pattern': [],
            'gesture_intensity': 0.0,
            'coordination_score': 0.0,
            'musical_expression': 0.0
        }

    def update_animation_time(self):
        """æ›´æ–°åŠ¨ç”»æ—¶é—´"""
        current_time = time.time()
        dt = current_time - self.last_update_time
        self.animation_time += dt
        self.last_update_time = current_time
        self.frame_count += 1

    def draw_professional_interface(self, frame: np.ndarray, system_state, performance_metrics,
                                  user_presence, gesture_data: Dict, active_regions: Dict,
                                  audio_controller=None, region_info: Dict = None) -> np.ndarray:
        """ç»˜åˆ¶å®Œæ•´çš„ä¸“ä¸šç•Œé¢"""
        try:
            # æ›´æ–°åŠ¨ç”»æ—¶é—´
            self.update_animation_time()

            display_frame = frame.copy()
            height, width = frame.shape[:2]

            # 1. ç»˜åˆ¶ä¸»èƒŒæ™¯å’Œç½‘æ ¼
            self._draw_background_and_grid(display_frame)

            # 2. ç»˜åˆ¶ä¸“ä¸šå¤´éƒ¨çŠ¶æ€æ 
            self._draw_professional_header(display_frame, system_state, performance_metrics,
                                         user_presence, audio_controller)

            # 3. ç»˜åˆ¶7å£°éƒ¨ä¸“ä¸šåŒºåŸŸç•Œé¢
            if region_info:
                self._draw_voice_regions_professional(display_frame, region_info['voice_regions'],
                                                    active_regions, region_info['central_control_region'])

            # 4. ç»˜åˆ¶ä¸“ä¸šéŸ³é¢‘ç”µå¹³è¡¨å’Œé¢‘è°±
            if audio_controller and audio_controller.is_initialized:
                track_volumes = audio_controller.get_track_volumes()
                self._draw_professional_audio_meters(display_frame, track_volumes, audio_controller)

            # 5. ç»˜åˆ¶æ‰‹åŠ¿åˆ†æå’ŒæŒ‡æŒ¥åˆ†æé¢æ¿
            self._draw_conducting_analysis_panel(display_frame, gesture_data, active_regions)

            # 6. ç»˜åˆ¶æ€§èƒ½ç›‘æ§é¢æ¿
            self._draw_performance_panel(display_frame, performance_metrics)

            # 7. ç»˜åˆ¶æ‰‹åŠ¿è½¨è¿¹å’Œæ•ˆæœ
            self._draw_gesture_trails_and_effects(display_frame, gesture_data, active_regions)

            # 8. ç»˜åˆ¶ç³»ç»Ÿæ§åˆ¶é¢æ¿
            self._draw_system_control_panel(display_frame)

            return display_frame

        except Exception as e:
            logging.error(f"Professional UI rendering error: {e}")
            return frame

    def _draw_background_and_grid(self, frame: np.ndarray):
        """ç»˜åˆ¶ä¸“ä¸šèƒŒæ™¯å’Œç½‘æ ¼"""
        height, width = frame.shape[:2]

        # æ¸å˜èƒŒæ™¯
        for y in range(height):
            alpha = 0.1 + 0.05 * np.sin(y / height * np.pi)
            color = tuple(int(c * alpha + self.colors['bg_dark'][i] * (1 - alpha))
                         for i, c in enumerate(self.colors['bg_medium']))
            cv2.line(frame, (0, y), (width, y), color, 1)

        # ç½‘æ ¼çº¿ (éŸ³ä¹åˆ¶ä½œé£æ ¼)
        grid_spacing = 50
        for x in range(0, width, grid_spacing):
            cv2.line(frame, (x, 0), (x, height), self.colors['grid_line'], 1)
        for y in range(0, height, grid_spacing):
            cv2.line(frame, (0, y), (width, y), self.colors['grid_line'], 1)

    def _draw_professional_header(self, frame: np.ndarray, system_state, performance_metrics,
                                user_presence, audio_controller=None):
        """ç»˜åˆ¶ä¸“ä¸šå¤´éƒ¨çŠ¶æ€æ """
        height, width = frame.shape[:2]
        header_height = self.layout['header_height']

        # å¤´éƒ¨èƒŒæ™¯æ¸å˜
        overlay = frame.copy()
        for y in range(header_height):
            alpha = 0.9 - (y / header_height) * 0.2
            color = tuple(int(c * alpha) for c in self.colors['bg_panel'])
            cv2.line(overlay, (0, y), (width, y), color, 1)
        cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)

        # é¡¶éƒ¨å¼ºè°ƒçº¿
        cv2.line(frame, (0, 0), (width, 0), self.colors['conducting_gold'], 3)

        # ä¸»æ ‡é¢˜åŒºåŸŸ
        title_area_height = 45
        title_bg = frame.copy()
        cv2.rectangle(title_bg, (0, 0), (width, title_area_height), self.colors['bg_dark'], -1)
        cv2.addWeighted(title_bg, 0.9, frame, 0.1, 0, frame)

        # ä¸»æ ‡é¢˜ (å¸¦éŸ³ä¹ç¬¦å·)
        title = "â™« BWV 29 in D - Professional Conductor Control System â™«"
        title_size = cv2.getTextSize(title, self.fonts['title'], self.font_scales['title'],
                                   self.thickness['normal'])[0]
        title_x = (width - title_size[0]) // 2

        # æ ‡é¢˜å‘å…‰æ•ˆæœ
        self._draw_text_with_glow(frame, title, (title_x, 28), self.fonts['title'],
                                self.font_scales['title'], self.colors['text_accent'],
                                self.thickness['normal'])

        # ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨ (å·¦ä¾§)
        self._draw_system_status_indicator(frame, 20, 60, system_state)

        # ç”¨æˆ·å­˜åœ¨çŠ¶æ€ (ä¸­å¤®)
        self._draw_user_presence_status(frame, width // 2 - 150, 60, user_presence)

        # å®æ—¶æ—¶é’Ÿå’Œæ’­æ”¾ä¿¡æ¯ (å³ä¾§)
        self._draw_playback_info(frame, width - 250, 60, audio_controller)

        # åˆ†éš”çº¿
        cv2.line(frame, (0, header_height - 2), (width, header_height - 2),
                self.colors['border_accent'], 2)

    def _draw_system_status_indicator(self, frame: np.ndarray, x: int, y: int, system_state):
        """ç»˜åˆ¶ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨"""
        # çŠ¶æ€é¢œè‰²æ˜ å°„
        state_colors = {
            'INITIALIZING': self.colors['warning_orange'],
            'WAITING_USER': self.colors['paused_blue'],
            'USER_DETECTED': self.colors['active_green'],
            'CONDUCTING': self.colors['conducting_gold'],
            'PAUSED': self.colors['paused_blue'],
            'ERROR': self.colors['error_red'],
        }

        state_name = system_state.value.upper() if hasattr(system_state, 'value') else str(system_state).upper()
        state_color = state_colors.get(state_name, self.colors['text_muted'])

        # çŠ¶æ€æŒ‡ç¤ºç¯ (å¸¦è„‰å†²æ•ˆæœ)
        pulse_intensity = 0.7 + 0.3 * abs(np.sin(self.animation_time * 3))
        pulse_color = tuple(int(c * pulse_intensity) for c in state_color)

        cv2.circle(frame, (x, y), 12, pulse_color, -1)
        cv2.circle(frame, (x, y), 14, state_color, 2)

        # çŠ¶æ€æ–‡å­—
        status_text = f"System: {state_name}"
        cv2.putText(frame, status_text, (x + 25, y + 5),
                   self.fonts['body'], self.font_scales['body'], state_color, self.thickness['normal'])

    def _draw_user_presence_status(self, frame: np.ndarray, x: int, y: int, user_presence):
        """ç»˜åˆ¶ç”¨æˆ·å­˜åœ¨çŠ¶æ€"""
        presence_text = "ğŸ­ CONDUCTOR ACTIVE" if user_presence.is_present else "â³ AWAITING CONDUCTOR"
        presence_color = self.colors['active_green'] if user_presence.is_present else self.colors['warning_orange']

        # çŠ¶æ€èƒŒæ™¯
        text_size = cv2.getTextSize(presence_text, self.fonts['subtitle'],
                                  self.font_scales['subtitle'], self.thickness['normal'])[0]

        # åœ†è§’çŸ©å½¢èƒŒæ™¯
        self._draw_rounded_rectangle(frame, (x - 10, y - 20), (x + text_size[0] + 10, y + 10),
                                   self.colors['bg_light'], presence_color)

        cv2.putText(frame, presence_text, (x, y),
                   self.fonts['subtitle'], self.font_scales['subtitle'], presence_color, self.thickness['normal'])

        # ç½®ä¿¡åº¦æ¡
        if user_presence.is_present:
            conf_bar_y = y + 15
            conf_bar_width = 200
            conf_bar_height = 6

            # èƒŒæ™¯
            cv2.rectangle(frame, (x, conf_bar_y), (x + conf_bar_width, conf_bar_y + conf_bar_height),
                         self.colors['bg_light'], -1)

            # ç½®ä¿¡åº¦å¡«å……
            conf_fill_width = int(conf_bar_width * user_presence.confidence)
            conf_color = self._interpolate_color(self.colors['error_red'], self.colors['active_green'],
                                               user_presence.confidence)
            cv2.rectangle(frame, (x, conf_bar_y), (x + conf_fill_width, conf_bar_y + conf_bar_height),
                         conf_color, -1)

            # ç½®ä¿¡åº¦æ•°å€¼
            conf_text = f"Confidence: {user_presence.confidence:.2f}"
            cv2.putText(frame, conf_text, (x, conf_bar_y + conf_bar_height + 15),
                       self.fonts['small'], self.font_scales['small'], self.colors['text_secondary'], 1)

    def _draw_playback_info(self, frame: np.ndarray, x: int, y: int, audio_controller=None):
        """ç»˜åˆ¶æ’­æ”¾ä¿¡æ¯"""
        if audio_controller:
            try:
                # æ’­æ”¾æ—¶é—´
                current_time = time.strftime("%H:%M:%S")
                time_text = f"Time: {current_time}"
                cv2.putText(frame, time_text, (x, y),
                           self.fonts['mono'], self.font_scales['body'], self.colors['text_primary'],
                           self.thickness['normal'])

                # æ’­æ”¾ä½ç½® (å¦‚æœå¯ç”¨)
                if hasattr(audio_controller, 'get_playback_position'):
                    position = audio_controller.get_playback_position()
                    position_text = f"Position: {position:.1f}s"
                    cv2.putText(frame, position_text, (x, y + 20),
                               self.fonts['mono'], self.font_scales['small'], self.colors['text_secondary'], 1)

                # æ’­æ”¾çŠ¶æ€æŒ‡ç¤º
                if hasattr(audio_controller, 'is_playing') and audio_controller.is_playing():
                    play_indicator = "â–¶ PLAYING"
                    play_color = self.colors['active_green']
                else:
                    play_indicator = "â¸ PAUSED"
                    play_color = self.colors['paused_blue']

                cv2.putText(frame, play_indicator, (x, y + 40),
                           self.fonts['body'], self.font_scales['small'], play_color, self.thickness['normal'])

            except Exception as e:
                logging.error(f"Error drawing playback info: {e}")

    def _draw_voice_regions_professional(self, frame: np.ndarray, voice_regions: Dict[str, Any],
                                       active_regions: Dict[str, Any], central_region: Dict[str, Any]):
        """ç»˜åˆ¶ä¸“ä¸š7å£°éƒ¨åŒºåŸŸç•Œé¢"""
        height, width = frame.shape[:2]
        header_height = self.layout['header_height']
        footer_height = self.layout['footer_height']
        sidebar_width = self.layout['sidebar_width']

        # å¯ç”¨åŒºåŸŸ (æ’é™¤å¤´éƒ¨ã€åº•éƒ¨å’Œå³ä¾§è¾¹æ )
        available_width = width - sidebar_width
        available_height = height - header_height - footer_height
        start_x = 0
        start_y = header_height

        # 7ä¸ªå£°éƒ¨åŒºåŸŸçš„ä¸“ä¸šå¸ƒå±€
        for i, (region_name, region_data) in enumerate(voice_regions.items()):
            bounds = region_data['bounds']
            voice_color = self.colors['voice_colors'][i % len(self.colors['voice_colors'])]

            # æ£€æŸ¥æ¿€æ´»çŠ¶æ€
            is_active = region_name in active_regions
            activation_strength = 0.0
            if is_active:
                activation_strength = active_regions[region_name].get('activation_strength', 0.0)

            # è½¬æ¢åæ ‡åˆ°å¯ç”¨åŒºåŸŸ
            x1 = int(start_x + bounds['x1'] * available_width)
            y1 = int(start_y + bounds['y1'] * available_height)
            x2 = int(start_x + bounds['x2'] * available_width)
            y2 = int(start_y + bounds['y2'] * available_height)

            # ç»˜åˆ¶å£°éƒ¨åŒºåŸŸ
            self._draw_voice_region_enhanced(frame, x1, y1, x2, y2, voice_color,
                                           region_name, i + 1, is_active, activation_strength)

        # ç»˜åˆ¶ä¸­å¤®æ§åˆ¶åŒºåŸŸ (æŒ‡æŒ¥å°)
        self._draw_central_podium(frame, central_region, active_regions, start_x, start_y,
                                available_width, available_height)

        # ç»˜åˆ¶å£°éƒ¨è¿æ¥çº¿
        self._draw_voice_connections(frame, voice_regions, active_regions, start_x, start_y,
                                   available_width, available_height)

    def _draw_voice_region_enhanced(self, frame: np.ndarray, x1: int, y1: int, x2: int, y2: int,
                                  voice_color: Tuple[int, int, int], region_name: str,
                                  voice_number: int, is_active: bool, activation_strength: float):
        """ç»˜åˆ¶å¢å¼ºçš„å£°éƒ¨åŒºåŸŸ"""

        # åŠ¨æ€è¾¹æ¡†æ•ˆæœ
        if is_active:
            # è„‰å†²æ•ˆæœ
            pulse = 0.7 + 0.3 * abs(np.sin(self.animation_time * 4))
            line_color = tuple(int(c * pulse) for c in voice_color)
            line_thickness = 4

            # å‘å…‰æ•ˆæœ
            for offset in range(8, 0, -1):
                alpha = 0.1 * (9 - offset)
                glow_color = tuple(int(c * alpha) for c in voice_color)
                cv2.rectangle(frame, (x1 - offset, y1 - offset),
                            (x2 + offset, y2 + offset), glow_color, 1)

            # æ¿€æ´»å¡«å……
            overlay = frame.copy()
            fill_alpha = 0.15 + 0.1 * activation_strength
            cv2.rectangle(overlay, (x1, y1), (x2, y2), voice_color, -1)
            cv2.addWeighted(overlay, fill_alpha, frame, 1 - fill_alpha, 0, frame)

        else:
            line_color = tuple(int(c * 0.6) for c in voice_color)
            line_thickness = 2

        # ä¸»è¾¹æ¡† (åœ†è§’)
        self._draw_rounded_rectangle(frame, (x1, y1), (x2, y2), None, line_color, line_thickness)

        # å£°éƒ¨ä¿¡æ¯é¢æ¿
        self._draw_voice_info_panel(frame, x1, y1, x2, y2, voice_color, region_name,
                                  voice_number, is_active, activation_strength)

    def _draw_voice_info_panel(self, frame: np.ndarray, x1: int, y1: int, x2: int, y2: int,
                             voice_color: Tuple[int, int, int], region_name: str,
                             voice_number: int, is_active: bool, activation_strength: float):
        """ç»˜åˆ¶å£°éƒ¨ä¿¡æ¯é¢æ¿"""

        panel_height = 80
        panel_y = y1 + 8

        # å£°éƒ¨ç¼–å·å¾½ç«  (ä¸“ä¸šè®¾è®¡)
        badge_size = 35
        badge_x = x1 + 12
        badge_y = panel_y + badge_size // 2

        # å¾½ç« èƒŒæ™¯ (æ¸å˜)
        cv2.circle(frame, (badge_x + badge_size // 2, badge_y), badge_size // 2, voice_color, -1)
        cv2.circle(frame, (badge_x + badge_size // 2, badge_y), badge_size // 2 + 2,
                  self.colors['text_primary'], 2)

        # å£°éƒ¨ç¼–å·
        badge_text = str(voice_number)
        text_size = cv2.getTextSize(badge_text, self.fonts['title'], self.font_scales['subtitle'],
                                  self.thickness['bold'])[0]
        text_x = badge_x + (badge_size - text_size[0]) // 2
        text_y = badge_y + text_size[1] // 2
        cv2.putText(frame, badge_text, (text_x, text_y),
                   self.fonts['title'], self.font_scales['subtitle'],
                   self.colors['bg_dark'], self.thickness['bold'])

        # å£°éƒ¨åç§° (å¤„ç†é•¿åç§°)
        voice_name = region_name.split('_')[0].replace('_', ' ')
        if len(voice_name) > 12:
            voice_name = voice_name[:12] + "..."

        name_x = badge_x + badge_size + 12
        cv2.putText(frame, voice_name, (name_x, panel_y + 20),
                   self.fonts['body'], self.font_scales['body'], voice_color, self.thickness['normal'])

        # ä¹å™¨ç±»å‹
        instrument_parts = region_name.split('_')
        if len(instrument_parts) > 1:
            instrument = instrument_parts[1]
            cv2.putText(frame, instrument, (name_x, panel_y + 40),
                       self.fonts['small'], self.font_scales['small'],
                       self.colors['text_secondary'], 1)

        # è°ƒæ€§ä¿¡æ¯
        if 'in_D' in region_name:
            cv2.putText(frame, "Key: D Major", (name_x, panel_y + 55),
                       self.fonts['small'], self.font_scales['tiny'],
                       self.colors['text_muted'], 1)

        # æ¿€æ´»çŠ¶æ€æŒ‡ç¤º
        if is_active:
            # æ¿€æ´»å¼ºåº¦æ¡
            strength_bar_x = x2 - 100
            strength_bar_y = panel_y + 8
            strength_bar_width = 80
            strength_bar_height = 12

            # èƒŒæ™¯
            cv2.rectangle(frame, (strength_bar_x, strength_bar_y),
                         (strength_bar_x + strength_bar_width, strength_bar_y + strength_bar_height),
                         self.colors['bg_light'], -1)

            # å¼ºåº¦å¡«å…… (æ¸å˜è‰²)
            fill_width = int(strength_bar_width * activation_strength)
            if fill_width > 0:
                # åˆ›å»ºæ¸å˜æ•ˆæœ
                for i in range(fill_width):
                    progress = i / strength_bar_width
                    color = self._interpolate_color(voice_color, self.colors['active_yellow'], progress * 0.3)
                    cv2.line(frame, (strength_bar_x + i, strength_bar_y),
                            (strength_bar_x + i, strength_bar_y + strength_bar_height), color, 1)

            # å¼ºåº¦æ•°å€¼
            strength_text = f"{activation_strength:.2f}"
            cv2.putText(frame, strength_text, (strength_bar_x, strength_bar_y + strength_bar_height + 15),
                       self.fonts['small'], self.font_scales['tiny'], voice_color, 1)

            # æ´»åŠ¨æŒ‡ç¤ºå™¨ (éŸ³ç¬¦ç¬¦å·)
            indicator_x = x2 - 20
            indicator_y = y1 + 20
            cv2.putText(frame, "â™ª", (indicator_x, indicator_y),
                       self.fonts['body'], self.font_scales['body'], self.colors['active_green'],
                       self.thickness['normal'])

    def _draw_central_podium(self, frame: np.ndarray, central_region: Dict[str, Any],
                           active_regions: Dict[str, Any], start_x: int, start_y: int,
                           available_width: int, available_height: int):
        """ç»˜åˆ¶ä¸­å¤®æŒ‡æŒ¥å°"""
        central_bounds = central_region['bounds']
        central_color = self.colors['conducting_gold']

        # æ£€æŸ¥ä¸­å¤®æ§åˆ¶æ˜¯å¦æ¿€æ´»
        central_active = any(h.get('active_region') == 'central_control' for h in active_regions.values())

        # åæ ‡è½¬æ¢
        x1 = int(start_x + central_bounds['x1'] * available_width)
        y1 = int(start_y + central_bounds['y1'] * available_height)
        x2 = int(start_x + central_bounds['x2'] * available_width)
        y2 = int(start_y + central_bounds['y2'] * available_height)

        # æŒ‡æŒ¥å°ç‰¹æ•ˆ
        if central_active:
            # å¼ºçƒˆå‘å…‰æ•ˆæœ
            for radius in range(15, 0, -1):
                alpha = 0.08 * (16 - radius)
                glow_color = tuple(int(c * alpha) for c in central_color)
                cv2.rectangle(frame, (x1 - radius, y1 - radius),
                            (x2 + radius, y2 + radius), glow_color, 1)

            # è„‰å†²è¾¹æ¡†
            pulse = 0.6 + 0.4 * abs(np.sin(self.animation_time * 2))
            border_color = tuple(int(c * pulse) for c in central_color)
            line_thickness = 6

            # æ¿€æ´»å¡«å…… (é‡‘è‰²æ¸å˜)
            overlay = frame.copy()
            cv2.rectangle(overlay, (x1, y1), (x2, y2), central_color, -1)
            cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)
        else:
            border_color = tuple(int(c * 0.7) for c in central_color)
            line_thickness = 3

        # ä¸»è¾¹æ¡† (åœ†è§’)
        self._draw_rounded_rectangle(frame, (x1, y1), (x2, y2), None, border_color, line_thickness)

        # æŒ‡æŒ¥å°å›¾æ ‡å’Œæ–‡å­—
        center_x = (x1 + x2) // 2
        center_y = (y1 + y2) // 2

        # æŒ‡æŒ¥æ£’å›¾æ ‡ (åŠ¨æ€)
        if central_active:
            # åŠ¨æ€æŒ‡æŒ¥æ£’
            baton_angle = np.sin(self.animation_time * 3) * 0.5
            baton_length = 40
            baton_end_x = center_x + int(baton_length * np.cos(baton_angle))
            baton_end_y = center_y - int(baton_length * np.sin(baton_angle))

            cv2.line(frame, (center_x, center_y), (baton_end_x, baton_end_y),
                    self.colors['text_primary'], 4)
            cv2.circle(frame, (center_x, center_y), 6, central_color, -1)
            cv2.circle(frame, (baton_end_x, baton_end_y), 3, self.colors['text_primary'], -1)

        # æŒ‡æŒ¥å°æ ‡ç­¾
        label = "ğŸ¼ CONDUCTOR PODIUM ğŸ¼" if central_active else "ğŸ¼ Conductor Podium"
        label_size = cv2.getTextSize(label, self.fonts['subtitle'], self.font_scales['subtitle'],
                                   self.thickness['normal'])[0]
        label_x = center_x - label_size[0] // 2
        label_y = y2 - 20

        # æ ‡ç­¾èƒŒæ™¯
        self._draw_rounded_rectangle(frame, (label_x - 8, label_y - 25),
                                   (label_x + label_size[0] + 8, label_y + 5),
                                   self.colors['bg_dark'], central_color)

        cv2.putText(frame, label, (label_x, label_y),
                   self.fonts['subtitle'], self.font_scales['subtitle'], central_color,
                   self.thickness['normal'])

    def _draw_professional_audio_meters(self, frame: np.ndarray, track_volumes: Dict[str, float],
                                      audio_controller=None):
        """ç»˜åˆ¶ä¸“ä¸šéŸ³é¢‘ç”µå¹³è¡¨"""
        height, width = frame.shape[:2]
        sidebar_width = self.layout['sidebar_width']
        header_height = self.layout['header_height']
        footer_height = self.layout['footer_height']

        # éŸ³é¢‘é¢æ¿ä½ç½® (å³ä¾§è¾¹æ )
        panel_x = width - sidebar_width
        panel_y = header_height + 20
        panel_width = sidebar_width - 20
        panel_height = height - header_height - footer_height - 40

        # é¢æ¿èƒŒæ™¯ (ä¸“ä¸šéŸ³é¢‘è®¾å¤‡é£æ ¼)
        overlay = frame.copy()
        cv2.rectangle(overlay, (panel_x, panel_y),
                     (panel_x + panel_width, panel_y + panel_height),
                     self.colors['bg_panel'], -1)
        cv2.addWeighted(overlay, 0.95, frame, 0.05, 0, frame)

        # é¢æ¿è¾¹æ¡†
        cv2.rectangle(frame, (panel_x, panel_y),
                     (panel_x + panel_width, panel_y + panel_height),
                     self.colors['border_accent'], 2)

        # æ ‡é¢˜
        title = "ğŸšï¸ AUDIO MIXING CONSOLE"
        title_y = panel_y + 25
        cv2.putText(frame, title, (panel_x + 10, title_y),
                   self.fonts['subtitle'], self.font_scales['subtitle'],
                   self.colors['text_accent'], self.thickness['normal'])

        # ä¸»è¾“å‡ºç”µå¹³
        master_y = title_y + 30
        if audio_controller:
            try:
                master_volume = max(track_volumes.values()) if track_volumes else 0.0
                self._draw_master_level_meter(frame, panel_x + 10, master_y,
                                            panel_width - 20, master_volume)
            except:
                pass

        # ä¸ªåˆ«å£°éƒ¨ç”µå¹³è¡¨
        meters_start_y = master_y + 80
        meter_height = 35
        meter_spacing = 40

        # æ›´æ–°å†å²æ•°æ®
        self._update_volume_history(track_volumes)

        # ç»˜åˆ¶æ¯ä¸ªå£°éƒ¨çš„ä¸“ä¸šç”µå¹³è¡¨
        for i, (track_name, volume) in enumerate(track_volumes.items()):
            meter_y = meters_start_y + i * meter_spacing

            if meter_y + meter_height > panel_y + panel_height - 60:
                break  # è¶…å‡ºé¢æ¿èŒƒå›´

            self._draw_professional_voice_meter(frame, panel_x + 10, meter_y,
                                               panel_width - 20, meter_height,
                                               track_name, volume, i)

        # éŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯
        self._draw_audio_statistics(frame, panel_x + 10, panel_y + panel_height - 50,
                                   panel_width - 20, track_volumes)

    def _draw_master_level_meter(self, frame: np.ndarray, x: int, y: int, width: int, volume: float):
        """ç»˜åˆ¶ä¸»è¾“å‡ºç”µå¹³è¡¨"""
        meter_height = 50

        # èƒŒæ™¯
        cv2.rectangle(frame, (x, y), (x + width, y + meter_height), self.colors['level_bg'], -1)
        cv2.rectangle(frame, (x, y), (x + width, y + meter_height), self.colors['border_accent'], 1)

        # ä¸“ä¸šåˆ†æ®µç”µå¹³æ˜¾ç¤º
        segments = 24
        segment_width = (width - 8) / segments
        segment_height = meter_height - 8

        for i in range(segments):
            segment_x = x + 4 + int(i * segment_width)
            segment_level = (i + 1) / segments

            if volume >= segment_level:
                # æ ¹æ®ç”µå¹³æ®µé€‰æ‹©é¢œè‰²
                if segment_level < 0.6:
                    color = self.colors['level_low']
                elif segment_level < 0.8:
                    color = self.colors['level_mid']
                elif segment_level < 0.9:
                    color = self.colors['level_high']
                else:
                    color = self.colors['level_peak']

                cv2.rectangle(frame, (segment_x, y + 4),
                             (segment_x + int(segment_width) - 1, y + 4 + segment_height),
                             color, -1)

        # æ•°å€¼æ˜¾ç¤º
        volume_text = f"MASTER: {volume:.3f}"
        cv2.putText(frame, volume_text, (x, y + meter_height + 18),
                   self.fonts['mono'], self.font_scales['small'],
                   self.colors['text_accent'], self.thickness['normal'])

    def _draw_professional_voice_meter(self, frame: np.ndarray, x: int, y: int, width: int,
                                     height: int, track_name: str, volume: float, index: int):
        """ç»˜åˆ¶ä¸“ä¸šå£°éƒ¨ç”µå¹³è¡¨"""
        # å£°éƒ¨é¢œè‰²
        voice_color = self.colors['voice_colors'][index % len(self.colors['voice_colors'])]

        # èƒŒæ™¯
        cv2.rectangle(frame, (x, y), (x + width, y + height), self.colors['level_bg'], -1)
        cv2.rectangle(frame, (x, y), (x + width, y + height), voice_color, 1)

        # ç”µå¹³æ¡
        bar_width = width - 80
        bar_x = x + 70
        bar_height = height - 8

        # èƒŒæ™¯æ¡
        cv2.rectangle(frame, (bar_x, y + 4), (bar_x + bar_width, y + 4 + bar_height),
                     self.colors['bg_dark'], -1)

        # éŸ³é‡å¡«å…… (å¸¦æ¸å˜)
        if volume > 0:
            fill_width = int(bar_width * volume)

            # åˆ›å»ºæ¸å˜å¡«å……
            for i in range(fill_width):
                progress = i / bar_width
                if progress < 0.7:
                    color = voice_color
                elif progress < 0.9:
                    color = self.colors['level_high']
                else:
                    color = self.colors['level_peak']

                cv2.line(frame, (bar_x + i, y + 4), (bar_x + i, y + 4 + bar_height), color, 1)

            # å³°å€¼æŒ‡ç¤º
            if volume > 0.9:
                peak_x = bar_x + fill_width - 3
                cv2.rectangle(frame, (peak_x, y + 4), (peak_x + 3, y + 4 + bar_height),
                             self.colors['level_peak'], -1)

        # å£°éƒ¨ç¼–å·å’Œåç§°
        voice_num = str(index + 1)
        cv2.putText(frame, voice_num, (x + 8, y + height - 8),
                   self.fonts['mono'], self.font_scales['body'], voice_color, self.thickness['bold'])

        # ç®€åŒ–çš„è½¨é“å
        short_name = track_name.split('_')[0][:8]
        cv2.putText(frame, short_name, (x + 25, y + height - 8),
                   self.fonts['small'], self.font_scales['tiny'], self.colors['text_secondary'], 1)

        # éŸ³é‡æ•°å€¼
        volume_text = f"{volume:.2f}"
        cv2.putText(frame, volume_text, (bar_x + bar_width + 5, y + height - 8),
                   self.fonts['mono'], self.font_scales['tiny'], self.colors['text_primary'], 1)

        # å³°å€¼ä¿æŒæŒ‡ç¤ºå™¨
        if volume > 0.8:
            cv2.circle(frame, (x + 50, y + height // 2), 3, self.colors['level_peak'], -1)

    def _update_volume_history(self, track_volumes: Dict[str, float]):
        """æ›´æ–°éŸ³é‡å†å²æ•°æ®"""
        current_time = time.time()
        for track_name, volume in track_volumes.items():
            if track_name not in self.history['volume_levels']:
                self.history['volume_levels'][track_name] = deque(maxlen=60)  # 1ç§’å†å²

            self.history['volume_levels'][track_name].append((current_time, volume))

    def _draw_audio_statistics(self, frame: np.ndarray, x: int, y: int, width: int,
                             track_volumes: Dict[str, float]):
        """ç»˜åˆ¶éŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯"""
        active_tracks = sum(1 for v in track_volumes.values() if v > 0.1)
        avg_volume = sum(track_volumes.values()) / len(track_volumes) if track_volumes else 0.0
        peak_volume = max(track_volumes.values()) if track_volumes else 0.0

        stats = [
            f"Active: {active_tracks}/{len(track_volumes)}",
            f"Average: {avg_volume:.2f}",
            f"Peak: {peak_volume:.2f}"
        ]

        for i, stat in enumerate(stats):
            cv2.putText(frame, stat, (x, y + i * 15),
                       self.fonts['small'], self.font_scales['tiny'],
                       self.colors['text_secondary'], 1)

    def _draw_conducting_analysis_panel(self, frame: np.ndarray, gesture_data: Dict,
                                      active_regions: Dict[str, Any]):
        """ç»˜åˆ¶æŒ‡æŒ¥åˆ†æé¢æ¿"""
        height, width = frame.shape[:2]
        footer_height = self.layout['footer_height']
        panel_y = height - footer_height

        # é¢æ¿èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, panel_y), (width, height), self.colors['bg_panel'], -1)
        cv2.addWeighted(overlay, 0.9, frame, 0.1, 0, frame)

        # é¡¶éƒ¨åˆ†éš”çº¿
        cv2.line(frame, (0, panel_y), (width, panel_y), self.colors['border_accent'], 2)

        # ä¸‰ä¸ªåˆ†æåŒºåŸŸ
        section_width = width // 3

        # 1. æ‰‹åŠ¿ç»Ÿè®¡åˆ†æ (å·¦ä¾§)
        self._draw_gesture_statistics_advanced(frame, 10, panel_y + 10,
                                             section_width - 20, footer_height - 20,
                                             gesture_data, active_regions)

        # 2. æŒ‡æŒ¥æŠ€å·§åˆ†æ (ä¸­å¤®)
        self._draw_conducting_technique_analysis(frame, section_width + 10, panel_y + 10,
                                               section_width - 20, footer_height - 20,
                                               gesture_data, active_regions)

        # 3. ç³»ç»Ÿæ§åˆ¶é¢æ¿ (å³ä¾§)
        self._draw_advanced_system_controls(frame, 2 * section_width + 10, panel_y + 10,
                                          section_width - 20, footer_height - 20)

    def _draw_gesture_statistics_advanced(self, frame: np.ndarray, x: int, y: int,
                                        width: int, height: int, gesture_data: Dict,
                                        active_regions: Dict[str, Any]):
        """ç»˜åˆ¶é«˜çº§æ‰‹åŠ¿ç»Ÿè®¡"""
        # æ ‡é¢˜
        cv2.putText(frame, "ğŸ¤² GESTURE ANALYTICS", (x, y + 20),
                   self.fonts['subtitle'], self.font_scales['subtitle'],
                   self.colors['text_accent'], self.thickness['normal'])

        stats_y = y + 45
        line_height = 20

        # ç»Ÿè®¡æ•°æ®
        hands_count = gesture_data.get('hands_detected', 0)
        active_count = len(active_regions)

        stats = [
            f"Hands Detected: {hands_count}",
            f"Active Regions: {active_count}/7",
            f"Detection Rate: {hands_count * 100 / 2:.0f}%",  # æœ€å¤š2åªæ‰‹
        ]

        # æ‰‹åŠ¿å¼ºåº¦å†å²
        if gesture_data.get('hands', []):
            avg_openness = sum(hand.get('openness', 0) for hand in gesture_data['hands']) / len(gesture_data['hands'])
            self.history['gesture_strength'].append(avg_openness)
            stats.append(f"Gesture Intensity: {avg_openness:.2f}")

        # ç»˜åˆ¶ç»Ÿè®¡æ–‡æœ¬
        for i, stat in enumerate(stats):
            color = self.colors['active_green'] if i == 0 and hands_count > 0 else self.colors['text_secondary']
            cv2.putText(frame, stat, (x, stats_y + i * line_height),
                       self.fonts['small'], self.font_scales['small'], color, 1)

        # æ‰‹åŠ¿å¼ºåº¦å›¾è¡¨ (è¿·ä½ å›¾è¡¨)
        if len(self.history['gesture_strength']) > 1:
            self._draw_mini_chart(frame, x, stats_y + len(stats) * line_height + 10,
                                width - 20, 30, list(self.history['gesture_strength']),
                                self.colors['active_green'])

    def _draw_conducting_technique_analysis(self, frame: np.ndarray, x: int, y: int,
                                          width: int, height: int, gesture_data: Dict,
                                          active_regions: Dict[str, Any]):
        """ç»˜åˆ¶æŒ‡æŒ¥æŠ€å·§åˆ†æ"""
        # æ ‡é¢˜
        cv2.putText(frame, "ğŸ¼ CONDUCTING ANALYSIS", (x, y + 20),
                   self.fonts['subtitle'], self.font_scales['subtitle'],
                   self.colors['text_accent'], self.thickness['normal'])

        analysis_y = y + 45
        line_height = 18

        # åˆ†ææŒ‡æŒ¥æŠ€å·§
        conducting_detected = len(active_regions) > 0
        technique_score = self._calculate_technique_score(gesture_data, active_regions)

        analysis = [
            f"Conducting Mode: {'ACTIVE' if conducting_detected else 'STANDBY'}",
            f"Technique Score: {technique_score:.1f}/10",
            f"Coordination: {'EXCELLENT' if technique_score > 8 else 'GOOD' if technique_score > 6 else 'DEVELOPING'}",
        ]

        # éŸ³ä¹è¡¨è¾¾åˆ†æ
        if active_regions:
            dynamic_range = self._calculate_dynamic_range(active_regions)
            analysis.append(f"Dynamic Range: {dynamic_range:.2f}")

            balance_score = self._calculate_balance_score(active_regions)
            analysis.append(f"Balance Score: {balance_score:.1f}/10")

        # ç»˜åˆ¶åˆ†ææ–‡æœ¬
        for i, text in enumerate(analysis):
            color = self.colors['conducting_gold'] if conducting_detected and i == 0 else self.colors['text_secondary']
            cv2.putText(frame, text, (x, analysis_y + i * line_height),
                       self.fonts['small'], self.font_scales['small'], color, 1)

        # æŠ€å·§è¯„åˆ†å¯è§†åŒ–
        score_bar_y = analysis_y + len(analysis) * line_height + 15
        self._draw_score_bar(frame, x, score_bar_y, width - 20, 12, technique_score / 10,
                           self.colors['conducting_gold'])

    def _draw_advanced_system_controls(self, frame: np.ndarray, x: int, y: int,
                                     width: int, height: int):
        """ç»˜åˆ¶é«˜çº§ç³»ç»Ÿæ§åˆ¶é¢æ¿"""
        # æ ‡é¢˜
        cv2.putText(frame, "âš™ï¸ SYSTEM CONTROLS", (x, y + 20),
                   self.fonts['subtitle'], self.font_scales['subtitle'],
                   self.colors['text_accent'], self.thickness['normal'])

        controls_y = y + 45
        line_height = 16

        # æ§åˆ¶æç¤º (åˆ†ç±»æ˜¾ç¤º)
        controls = [
            "PLAYBACK:",
            "  SPACE - Play/Pause",
            "  R - Reset System",
            "",
            "DISPLAY:",
            "  D - Debug Toggle",
            "  F - Fullscreen",
            "  H - Help Toggle",
            "",
            "VOLUME:",
            "  1-9 - Direct Control",
            "  0 - Mute All"
        ]

        for i, control in enumerate(controls):
            if control.startswith("  "):
                color = self.colors['text_secondary']
                font_scale = self.font_scales['tiny']
            elif control.endswith(":"):
                color = self.colors['text_accent']
                font_scale = self.font_scales['small']
            elif control == "":
                continue
            else:
                color = self.colors['text_muted']
                font_scale = self.font_scales['tiny']

            if i * line_height < height - 60:
                cv2.putText(frame, control, (x, controls_y + i * line_height),
                           self.fonts['small'], font_scale, color, 1)

    def _draw_performance_panel(self, frame: np.ndarray, performance_metrics):
        """ç»˜åˆ¶æ€§èƒ½ç›‘æ§é¢æ¿"""
        # åœ¨å³ä¸Šè§’ç»˜åˆ¶å°å‹æ€§èƒ½é¢æ¿
        height, width = frame.shape[:2]
        panel_x = width - 200
        panel_y = 130  # åœ¨headerä¸‹æ–¹

        # ç®€æ´çš„æ€§èƒ½æ˜¾ç¤º
        perf_data = [
            f"FPS: {performance_metrics.fps:.1f}",
            f"Latency: {performance_metrics.gesture_latency:.1f}ms",
            f"Memory: {performance_metrics.memory_usage:.1f}%"
        ]

        # æ›´æ–°FPSå†å²
        self.history['fps_history'].append(performance_metrics.fps)

        for i, data in enumerate(perf_data):
            color = self._get_performance_color(performance_metrics.fps if i == 0 else
                                              (50 - performance_metrics.gesture_latency) if i == 1 else
                                              (100 - performance_metrics.memory_usage),
                                              30 if i == 0 else 0 if i == 1 else 0,
                                              60 if i == 0 else 50 if i == 1 else 80)

            cv2.putText(frame, data, (panel_x, panel_y + i * 18),
                       self.fonts['mono'], self.font_scales['tiny'], color, 1)

    def _draw_gesture_trails_and_effects(self, frame: np.ndarray, gesture_data: Dict,
                                       active_regions: Dict[str, Any]):
        """ç»˜åˆ¶æ‰‹åŠ¿è½¨è¿¹å’Œç‰¹æ•ˆ"""
        # æ›´æ–°æ‰‹éƒ¨ä½ç½®å†å²
        if gesture_data.get('hands', []):
            for hand in gesture_data['hands']:
                hand_pos = hand.get('position', (0, 0))
                self.history['hand_positions'].append(hand_pos)

        # ç»˜åˆ¶æ‰‹åŠ¿è½¨è¿¹ (å¦‚æœæœ‰å†å²ä½ç½®)
        if len(self.history['hand_positions']) > 1:
            positions = list(self.history['hand_positions'])
            height, width = frame.shape[:2]

            for i in range(1, len(positions)):
                if i < len(positions) - 10:  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ªç‚¹
                    continue

                alpha = (i - (len(positions) - 10)) / 10  # æ¸å˜é€æ˜åº¦

                pos1 = (int(positions[i-1][0] * width), int(positions[i-1][1] * height))
                pos2 = (int(positions[i][0] * width), int(positions[i][1] * height))

                trail_color = tuple(int(c * alpha) for c in self.colors['active_green'])
                cv2.line(frame, pos1, pos2, trail_color, 2)

    def _draw_system_control_panel(self, frame: np.ndarray):
        """ç»˜åˆ¶ç³»ç»Ÿæ§åˆ¶é¢æ¿"""
        # è¿™ä¸ªæ–¹æ³•å¯ä»¥ç”¨æ¥ç»˜åˆ¶é¢å¤–çš„ç³»ç»Ÿæ§åˆ¶å…ƒç´ 
        # å¦‚å¿«æ·é”®æç¤ºã€çŠ¶æ€æŒ‡ç¤ºå™¨ç­‰
        pass

    # è¾…åŠ©æ–¹æ³•
    def _draw_rounded_rectangle(self, frame: np.ndarray, pt1: Tuple[int, int],
                              pt2: Tuple[int, int], fill_color: Optional[Tuple[int, int, int]] = None,
                              border_color: Optional[Tuple[int, int, int]] = None,
                              thickness: int = 1, radius: int = 8):
        """ç»˜åˆ¶åœ†è§’çŸ©å½¢"""
        x1, y1 = pt1
        x2, y2 = pt2

        if fill_color:
            cv2.rectangle(frame, (x1 + radius, y1), (x2 - radius, y2), fill_color, -1)
            cv2.rectangle(frame, (x1, y1 + radius), (x2, y2 - radius), fill_color, -1)
            cv2.circle(frame, (x1 + radius, y1 + radius), radius, fill_color, -1)
            cv2.circle(frame, (x2 - radius, y1 + radius), radius, fill_color, -1)
            cv2.circle(frame, (x1 + radius, y2 - radius), radius, fill_color, -1)
            cv2.circle(frame, (x2 - radius, y2 - radius), radius, fill_color, -1)

        if border_color:
            # ç»˜åˆ¶åœ†è§’è¾¹æ¡† (ç®€åŒ–ç‰ˆ)
            cv2.rectangle(frame, pt1, pt2, border_color, thickness)

    def _draw_text_with_glow(self, frame: np.ndarray, text: str, position: Tuple[int, int],
                           font, font_scale: float, color: Tuple[int, int, int], thickness: int):
        """ç»˜åˆ¶å¸¦å‘å…‰æ•ˆæœçš„æ–‡å­—"""
        x, y = position

        # å‘å…‰æ•ˆæœ (å¤šå±‚é˜´å½±)
        glow_offsets = [(2, 2), (1, 1), (-1, -1), (-2, -2), (2, -2), (-2, 2)]
        glow_color = tuple(int(c * 0.3) for c in color)

        for offset in glow_offsets:
            cv2.putText(frame, text, (x + offset[0], y + offset[1]),
                       font, font_scale, glow_color, thickness)

        # ä¸»æ–‡å­—
        cv2.putText(frame, text, (x, y), font, font_scale, color, thickness)

    def _interpolate_color(self, color1: Tuple[int, int, int], color2: Tuple[int, int, int],
                          factor: float) -> Tuple[int, int, int]:
        """åœ¨ä¸¤ä¸ªé¢œè‰²ä¹‹é—´æ’å€¼"""
        factor = max(0.0, min(1.0, factor))
        return tuple(int(c1 + (c2 - c1) * factor) for c1, c2 in zip(color1, color2))

    def _get_performance_color(self, value: float, min_good: float, max_good: float) -> Tuple[int, int, int]:
        """æ ¹æ®æ€§èƒ½å€¼è·å–é¢œè‰²"""
        if min_good <= value <= max_good:
            return self.colors['active_green']
        elif value >= min_good * 0.7:
            return self.colors['warning_orange']
        else:
            return self.colors['error_red']

    def _draw_mini_chart(self, frame: np.ndarray, x: int, y: int, width: int, height: int,
                        data: List[float], color: Tuple[int, int, int]):
        """ç»˜åˆ¶è¿·ä½ å›¾è¡¨"""
        if len(data) < 2:
            return

        # æ ‡å‡†åŒ–æ•°æ®
        max_val = max(data) if max(data) > 0 else 1.0
        min_val = min(data)
        range_val = max_val - min_val if max_val > min_val else 1.0

        # ç»˜åˆ¶èƒŒæ™¯
        cv2.rectangle(frame, (x, y), (x + width, y + height), self.colors['bg_dark'], -1)
        cv2.rectangle(frame, (x, y), (x + width, y + height), color, 1)

        # ç»˜åˆ¶æ•°æ®çº¿
        step = width / (len(data) - 1)
        for i in range(1, len(data)):
            x1 = int(x + (i - 1) * step)
            y1 = int(y + height - ((data[i-1] - min_val) / range_val * height))
            x2 = int(x + i * step)
            y2 = int(y + height - ((data[i] - min_val) / range_val * height))

            cv2.line(frame, (x1, y1), (x2, y2), color, 2)

    def _draw_score_bar(self, frame: np.ndarray, x: int, y: int, width: int, height: int,
                       score: float, color: Tuple[int, int, int]):
        """ç»˜åˆ¶è¯„åˆ†æ¡"""
        # èƒŒæ™¯
        cv2.rectangle(frame, (x, y), (x + width, y + height), self.colors['bg_dark'], -1)
        cv2.rectangle(frame, (x, y), (x + width, y + height), self.colors['border_accent'], 1)

        # è¯„åˆ†å¡«å……
        fill_width = int(width * score)
        if fill_width > 0:
            cv2.rectangle(frame, (x, y), (x + fill_width, y + height), color, -1)

    def _calculate_technique_score(self, gesture_data: Dict, active_regions: Dict) -> float:
        """è®¡ç®—æŒ‡æŒ¥æŠ€å·§è¯„åˆ†"""
        score = 5.0  # åŸºç¡€åˆ†

        # æ‰‹åŠ¿æ£€æµ‹è´¨é‡
        hands_count = gesture_data.get('hands_detected', 0)
        if hands_count > 0:
            score += 2.0

        # åŒºåŸŸæ¿€æ´»æ•°é‡
        active_count = len(active_regions)
        if active_count > 0:
            score += min(3.0, active_count * 0.5)

        return min(10.0, score)

    def _calculate_dynamic_range(self, active_regions: Dict) -> float:
        """è®¡ç®—åŠ¨æ€èŒƒå›´"""
        if not active_regions:
            return 0.0

        strengths = [data.get('activation_strength', 0.0) for data in active_regions.values()]
        return max(strengths) - min(strengths) if len(strengths) > 1 else 0.0

    def _calculate_balance_score(self, active_regions: Dict) -> float:
        """è®¡ç®—å¹³è¡¡è¯„åˆ†"""
        if not active_regions:
            return 0.0

        # ç®€åŒ–çš„å¹³è¡¡è¯„åˆ†ç®—æ³•
        strengths = [data.get('activation_strength', 0.0) for data in active_regions.values()]
        avg_strength = sum(strengths) / len(strengths)
        variance = sum((s - avg_strength) ** 2 for s in strengths) / len(strengths)

        # æ–¹å·®è¶Šå°ï¼Œå¹³è¡¡æ€§è¶Šå¥½
        balance_score = max(0.0, 10.0 - variance * 10)
        return min(10.0, balance_score)

    def _draw_voice_connections(self, frame: np.ndarray, voice_regions: Dict[str, Any],
                              active_regions: Dict[str, Any], start_x: int, start_y: int,
                              available_width: int, available_height: int):
        """ç»˜åˆ¶å£°éƒ¨é—´è¿æ¥çº¿ (å’Œå£°å…³ç³»å¯è§†åŒ–)"""
        # åªåœ¨æœ‰æ´»åŠ¨å£°éƒ¨æ—¶æ˜¾ç¤ºè¿æ¥
        active_voice_positions = []

        for region_name, region_data in voice_regions.items():
            if region_name in active_regions:
                bounds = region_data['bounds']
                center_x = int(start_x + (bounds['x1'] + bounds['x2']) * available_width / 2)
                center_y = int(start_y + (bounds['y1'] + bounds['y2']) * available_height / 2)
                active_voice_positions.append((center_x, center_y))

        # ç»˜åˆ¶è¿æ¥çº¿
        if len(active_voice_positions) > 1:
            for i, pos1 in enumerate(active_voice_positions):
                for j, pos2 in enumerate(active_voice_positions[i+1:], i+1):
                    # åŠé€æ˜è¿æ¥çº¿ï¼Œå¸¦åŠ¨ç”»æ•ˆæœ
                    alpha = 0.3 + 0.2 * abs(np.sin(self.animation_time + i + j))
                    line_color = tuple(int(c * alpha) for c in self.colors['active_green'])
                    cv2.line(frame, pos1, pos2, line_color, 1)